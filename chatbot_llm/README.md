# Experimento LLM - Duas VersÃµes de ConfiguraÃ§Ã£o

## ğŸ“‹ DescriÃ§Ã£o
Experimento com Large Language Model (LLM) desenvolvendo duas versÃµes:
1. **VersÃ£o Conservadora**: Respostas menores e mais coerentes
2. **VersÃ£o Criativa**: Respostas mais abertas e criativas

## ğŸ”§ DependÃªncias
```bash
pip install transformers torch accelerate
```

## ğŸ“¦ InstalaÃ§Ã£o
1. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

2. Execute as duas versÃµes:
```bash
# VersÃ£o conservadora
python llm_conservative.py

# VersÃ£o criativa
python llm_creative.py
```

## ğŸ›ï¸ ParÃ¢metros de ConfiguraÃ§Ã£o

### VersÃ£o Conservadora
- **Temperature**: 0.3 (baixa) - Respostas mais determinÃ­sticas
- **Max Length**: 50 tokens - Respostas curtas
- **Top-p**: 0.8 - VocabulÃ¡rio mais restrito
- **Repetition Penalty**: 1.2 - Evita repetiÃ§Ãµes

### VersÃ£o Criativa
- **Temperature**: 0.9 (alta) - Respostas mais variadas
- **Max Length**: 150 tokens - Respostas mais longas
- **Top-p**: 0.95 - VocabulÃ¡rio mais amplo
- **Repetition Penalty**: 1.1 - Permite mais criatividade

## ğŸ” ExplicaÃ§Ã£o dos ParÃ¢metros

### Temperature
- **Baixa (0.3)**: Torna o modelo mais conservador e previsÃ­vel
- **Alta (0.9)**: Permite maior aleatoriedade e criatividade

### Max Length
- **Curto (50)**: ForÃ§a respostas concisas e diretas
- **Longo (150)**: Permite elaboraÃ§Ã£o de ideias

### Top-p (Nucleus Sampling)
- **0.8**: Considera tokens que somam 80% da probabilidade
- **0.95**: Considera tokens que somam 95% da probabilidade

### Repetition Penalty
- **1.2**: Penaliza mais repetiÃ§Ãµes, forÃ§a diversidade
- **1.1**: PenalizaÃ§Ã£o suave, permite alguns padrÃµes

## ğŸ–¼ï¸ Capturas de Tela
![LLM Conservador](../assets/llm_conservative_demo.png)
![LLM Criativo](../assets/llm_creative_demo.png)
